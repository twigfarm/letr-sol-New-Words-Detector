{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dqZ9OPn8EG6N"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install emoji\n",
        "# !pip install soynlp\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8KmJPkvELLH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "from soynlp.normalizer import repeat_normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l8tHUD8ClHL3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "import emoji\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "def change(txt):\n",
        "    result = re.sub('\\'', '', txt)[1:-1].split()\n",
        "    return (result)\n",
        "\n",
        "def change2(txt):\n",
        "    return (ast.literal_eval(txt))\n",
        "\n",
        "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
        "url_pattern = re.compile(\n",
        "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "\n",
        "def clean(x):\n",
        "    x = pattern.sub(' ', x)\n",
        "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
        "    x = url_pattern.sub('', x)\n",
        "    x = x.strip()\n",
        "    x = repeat_normalize(x, num_repeats=2)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gaRAEOzZEL9D"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "MODEL_NAME = \"beomi/KcELECTRA-base-v2022\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "with open('./all_ner_tags_tag2id.json', 'r') as f:\n",
        "  tag_to_index = json.load(f)\n",
        "\n",
        "with open('./all_ner_tags_id2tag.json', 'r') as f:\n",
        "  index_to_tag = json.load(f)\n",
        "\n",
        "pad_token_id = tokenizer.pad_token_id\n",
        "cls_token_id = tokenizer.cls_token_id\n",
        "sep_token_id = tokenizer.sep_token_id\n",
        "pad_token_label_id = tag_to_index['O']\n",
        "cls_token_label_id = tag_to_index['O']\n",
        "sep_token_label_id = tag_to_index['O']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pfXMbXJ_uXOK"
      },
      "outputs": [],
      "source": [
        "with open('./all_ner_tag_info.json', 'r') as f:\n",
        "  raw_data = json.load(f)\n",
        "\n",
        "train_sentence_data =[]\n",
        "for idx1, s in enumerate(raw_data['sentence']):\n",
        "  tmp = []\n",
        "  remove_idx = []\n",
        "  for idx2, w in enumerate(s):\n",
        "    clean_text = clean(w)\n",
        "    if len(clean(w)) != 0:\n",
        "      tmp.append(clean_text)\n",
        "    else:\n",
        "      remove_idx.append(idx2)\n",
        "\n",
        "  add_idx=0\n",
        "  for idx2 in remove_idx:\n",
        "    raw_data['tag'][idx1].pop(idx2 + add_idx)\n",
        "    add_idx-=1\n",
        "\n",
        "  train_sentence_data.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFXUkywrweDa",
        "outputId": "34ed31f6-6f11-4f94-e219-69e06848aede"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "464545"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_sentence_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VqqtG49Vsb_v"
      },
      "outputs": [],
      "source": [
        "split_point = int(len(raw_data['sentence']) * 0.8)\n",
        "\n",
        "train_sentence = train_sentence_data[:split_point]\n",
        "train_label = raw_data['tag'][:split_point]\n",
        "\n",
        "test_sentence = train_sentence_data[split_point:]\n",
        "test_label = raw_data['tag'][split_point:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(371636, 92909)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_sentence), len(test_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6yyC7muOFE57"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def convert_features(examples, labels, max_seq_len, tokenizer, pad_token_id_for_segment = 0, pad_token_id_for_label = -100):\n",
        "\n",
        "    cls_token = tokenizer.cls_token\n",
        "    sep_token = tokenizer.sep_token\n",
        "    pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    tokenizer_data, data_labels = [], []\n",
        "\n",
        "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
        "        tokens = []\n",
        "        labels_ids = []\n",
        "        for one_word, label_token in zip(example, label):\n",
        "            subword_tokens = tokenizer.tokenize(one_word)\n",
        "            tokens.extend(subword_tokens)\n",
        "\n",
        "            labels_ids.extend([tag_to_index[label_token]] + [pad_token_id_for_label] * (len(subword_tokens) - 1))\n",
        "\n",
        "        special_tokens_count = 2\n",
        "        if len(tokens) > max_seq_len - special_tokens_count:\n",
        "            tokens = tokens[:(max_seq_len - special_tokens_count)]\n",
        "            labels_ids = labels_ids[:(max_seq_len - special_tokens_count)]\n",
        "\n",
        "        tokens += [sep_token]\n",
        "        labels_ids += [pad_token_id_for_label]\n",
        "\n",
        "        tokens = [cls_token] + tokens\n",
        "        labels_ids = [pad_token_id_for_label] + labels_ids\n",
        "\n",
        "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        attention_mask = [1] * len(input_id)\n",
        "        padding_count = max_seq_len - len(input_id)\n",
        "        input_id = input_id + ([pad_token_id] * padding_count)\n",
        "        attention_mask = attention_mask + ([0] * padding_count)\n",
        "\n",
        "        token_type_id = [pad_token_id_for_segment] * max_seq_len\n",
        "\n",
        "        label = labels_ids + ([pad_token_id_for_label] * padding_count)\n",
        "\n",
        "        assert len(input_id) == max_seq_len, \"input length Error {} vs {}\".format(len(input_id), max_seq_len)\n",
        "        assert len(input_id) == max_seq_len, \"attention mask Error {} vs {}\".format(len(attention_mask), max_seq_len)\n",
        "        assert len(input_id) == max_seq_len, \"type token Error {} vs {}\".format(len(label), max_seq_len)\n",
        "\n",
        "        tokenizer_data.append({\n",
        "        'input_ids' : input_id,\n",
        "        'attention_mask' : attention_mask,\n",
        "        'token_type_ids' : token_type_id\n",
        "        })\n",
        "        data_labels.append(label)\n",
        "\n",
        "    return tokenizer_data, data_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkWPI5HqFIv9",
        "outputId": "5417ac7a-9647-4555-f3b2-6c3a6cdf851f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92909/92909 [00:22<00:00, 4192.43it/s]\n"
          ]
        }
      ],
      "source": [
        "# tokenizer_train_sentence, tokenizer_train_labels =convert_features(train_sentence, train_label, 128, tokenizer=tokenizer)\n",
        "tokenizer_test_sentence, tokenizer_test_labels =convert_features(test_sentence, test_label, 128, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JhOjbsyeHiBG"
      },
      "outputs": [],
      "source": [
        "class TokenDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encoding = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key : torch.tensor(val) for key, val in self.encoding[idx].items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EctWMLBRG_se"
      },
      "outputs": [],
      "source": [
        "# train_data_set = TokenDataset(tokenizer_train_sentence, tokenizer_train_labels)\n",
        "test_data_set = TokenDataset(tokenizer_test_sentence, tokenizer_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S6Ddwz9uFbx3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# device = torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'train_data_set'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m17\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'train_data_set'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import math\n",
        "traing_args = TrainingArguments(\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = 64,\n",
        "    per_device_eval_batch_size = 32,\n",
        "    logging_dir = './loss',\n",
        "    logging_steps = 500,\n",
        "    learning_rate = 3e-5,\n",
        "    weight_decay = 0.01,\n",
        "    save_total_limit = 2,\n",
        "    save_strategy = 'steps',\n",
        "    evaluation_strategy = 'steps',\n",
        "    save_steps= 500,\n",
        "    eval_steps= 500,\n",
        "    warmup_steps= math.ceil(len(train_data_set) * 5 / 64 * 0.1),\n",
        "    seed=15,\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "# 손실함수를 따로 정의해줄 필요가 있어서 기본 트레이너에서 손실함수만 수정한 부분\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss_fn = torch.nn.CrossEntropyLoss().to(device = device)\n",
        "\n",
        "        active_loss = torch.reshape(labels, (-1,)) != -100 \n",
        "        tensor_size = active_loss.size()[0]\n",
        "        active_logits_loss = active_loss.reshape(tensor_size, 1).expand(tensor_size, logits.size()[2])\n",
        "\n",
        "        reduced_logits = torch.masked_select(torch.reshape(logits, (-1, logits.size()[2])), active_logits_loss)\n",
        "        reduced_logits = reduced_logits.reshape(-1, logits.size()[2])\n",
        "        labels = torch.masked_select(torch.reshape(labels, (-1,)), active_loss)\n",
        "\n",
        "        loss = loss_fn(reduced_logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1-dy60VFwVE",
        "outputId": "18e5ee93-2275-4e3a-e7fb-dac8c578d7bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForTokenClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
            "- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels = len(tag_to_index))\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dQw2cfSZHYI_"
      },
      "outputs": [],
      "source": [
        "trainer = CustomTrainer(\n",
        "    model = model,\n",
        "    args = traing_args,\n",
        "    train_dataset=train_data_set,\n",
        "    eval_dataset=test_data_set,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "vXh0lMvsGYb_",
        "outputId": "44deddbc-406c-4dca-cf09-f71ca0957b69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sol4/anaconda3/envs/sol4/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10500' max='14520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10500/14520 3:42:59 < 1:25:23, 0.78 it/s, Epoch 3/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.315200</td>\n",
              "      <td>0.126782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.202800</td>\n",
              "      <td>0.072038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.151200</td>\n",
              "      <td>0.050982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.122700</td>\n",
              "      <td>0.043243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.037843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.093500</td>\n",
              "      <td>0.034663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.031754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.076000</td>\n",
              "      <td>0.029880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.076100</td>\n",
              "      <td>0.031226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.070400</td>\n",
              "      <td>0.028179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.027313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.060600</td>\n",
              "      <td>0.026657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>0.027505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.048900</td>\n",
              "      <td>0.027887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.050800</td>\n",
              "      <td>0.026992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.047200</td>\n",
              "      <td>0.026491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.049700</td>\n",
              "      <td>0.026590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.041400</td>\n",
              "      <td>0.028216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.027949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.035600</td>\n",
              "      <td>0.027785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.034600</td>\n",
              "      <td>0.026901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10500, training_loss=0.1343307604108538, metrics={'train_runtime': 13382.6613, 'train_samples_per_second': 138.85, 'train_steps_per_second': 1.085, 'total_flos': 8.779748238901555e+16, 'train_loss': 0.1343307604108538, 'epoch': 3.62})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "GfDxS-zkGtMF",
        "outputId": "67a603e0-fa77-42b5-8dda-ba8126a76e8d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "import torch\n",
        "device = torch.device('cuda:0')\n",
        "model = AutoModelForTokenClassification.from_pretrained('./results/checkpoint-8000')\n",
        "model.to(device)\n",
        "trainer = Trainer(\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nLxaQmkIOoqq",
        "outputId": "fc9ca39c-4715-4021-c5c6-a760ba37062e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sol4/anaconda3/envs/sol4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = trainer.predict(test_data_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tcSBFhPZOvvb"
      },
      "outputs": [],
      "source": [
        "preds = np.argmax(y_pred.predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds[109]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_to_tag[-100] = tokenizer.pad_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_to_tag2 = {key : 'B-'+value for key, value in index_to_tag.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_to_tag2['0'] = 'O'\n",
        "index_to_tag2[-100] = tokenizer.pad_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[CLS] 우리도 나중에 멀지 않아서 통일'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(test_data_set[107]['input_ids'][:6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " array([-100,    0,    0,    0,    0,    0,    0, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds[109], y_pred.label_ids[107]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_lst = []\n",
        "for pred_labels, pred_pred in zip(y_pred.label_ids, preds):\n",
        "    tmp =[]\n",
        "    for idx in range(128):\n",
        "        if pred_labels[idx] != -100:\n",
        "            tmp.append(index_to_tag2[str(pred_pred[idx])])\n",
        "        else:\n",
        "            tmp.append(index_to_tag2[-100])\n",
        "    pred_lst.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFLnT6i4PplF",
        "outputId": "ebb2a335-5351-4f78-82c7-7e9dea138cb4"
      },
      "outputs": [],
      "source": [
        "true_y = []\n",
        "for l in tokenizer_test_labels:\n",
        "  tmp = []\n",
        "  for i, l_id in enumerate(l):\n",
        "    if l_id != -100:\n",
        "      tmp.append(index_to_tag2[str(l_id)])\n",
        "    else:\n",
        "          tmp.append(index_to_tag2[-100])\n",
        "  true_y.append(tmp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_pred, tmp_turey = [], []\n",
        "for tmp_p, tmp_y in zip(pred_lst, true_y):\n",
        "    tmp1 = [value for value in tmp_p if value != '[PAD]']\n",
        "    tmp2 = [value for value in tmp_y if value != '[PAD]']\n",
        "\n",
        "    tmp_pred.append(tmp1), tmp_turey.append(tmp2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(92909, 92909, ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tmp_pred), len(tmp_turey), tmp_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "true_y = MultiLabelBinarizer().fit_transform(true_y)\n",
        "pred_lst = MultiLabelBinarizer().fit_transform(pred_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol4FTJqqTudl",
        "outputId": "03acd6ca-13b8-4fd8-c77d-ddfd29ff22b9"
      },
      "outputs": [],
      "source": [
        "score = f1_score(true_y, pred_lst, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AF       0.82      0.80      0.81       164\n",
            "         AFA       0.81      0.75      0.78       425\n",
            "         AFW       0.05      0.14      0.08        14\n",
            "          AM       0.85      0.86      0.85       461\n",
            "          CV       0.84      0.90      0.87      2805\n",
            "          DT       0.93      0.95      0.94       993\n",
            "          EV       0.73      0.64      0.68        74\n",
            "          FD       0.63      0.61      0.62       112\n",
            "          LC       0.67      0.60      0.63        90\n",
            "         LCG       0.83      0.89      0.86       105\n",
            "         LCP       0.90      0.92      0.91       548\n",
            "          MT       0.62      0.67      0.64        27\n",
            "         OGG       0.70      0.70      0.70       304\n",
            "          PS       0.83      0.83      0.83       483\n",
            "          PT       0.72      0.64      0.68        73\n",
            "          QT       0.87      0.94      0.90      1470\n",
            "          TI       0.87      0.94      0.91       155\n",
            "          TM       0.71      0.72      0.71       136\n",
            "         TMI       0.79      0.85      0.82       289\n",
            "        TMIG       0.33      1.00      0.50         3\n",
            "         TMM       0.90      0.90      0.90       408\n",
            "          TR       0.24      0.31      0.27        35\n",
            "\n",
            "   micro avg       0.84      0.87      0.86      9174\n",
            "   macro avg       0.71      0.75      0.72      9174\n",
            "weighted avg       0.84      0.87      0.86      9174\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(tmp_turey, tmp_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seq2tag(label_ids, pred_ids):\n",
        "    label_list = []\n",
        "    pred_list = []\n",
        "    for i in range(0, len(label_ids)): \n",
        "        label_tag = []\n",
        "        pred_tag = []\n",
        "        for label_index, pred_index in zip(label_ids[i], pred_ids[i]):\n",
        "            if label_index != -100:\n",
        "                label_tag.append(index_to_tag[str(label_index)])\n",
        "                pred_tag.append(index_to_tag[str(pred_index)])\n",
        "            label_list.append(label_tag)\n",
        "            pred_list.append(pred_tag)\n",
        "    return label_list, pred_list\n",
        "\n",
        "label_list, pred_list = seq2tag(tokenizer_test_labels, preds)\n",
        "        \n",
        "print(classification_report(label_list, pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_list[0], pred_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['O', 'CV', 'AFA', 'DT', 'OGG', 'QT', 'AM', 'LCP', 'TMM', 'MT', 'TI', 'TMI', 'PS', 'PT', 'AF', 'AFW', 'TMIG', 'TR', 'LCG', 'TM', 'FD', 'LC', 'EV'])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tag_to_index.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "print(classification_report(label_list, pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['O', 'CV', 'AFA', 'DT', 'OGG', 'QT', 'AM', 'LCP', 'TMM', 'MT', 'TI', 'TMI', 'PS', 'PT', 'AF', 'AFW', 'TMIG', 'TR', 'LCG', 'TM', 'FD', 'LC', 'EV'])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tag_to_index.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
